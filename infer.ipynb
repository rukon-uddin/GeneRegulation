{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['0', '1', '0', '0', '1', '1', '0', '1', '0', '0'],\n",
       " ['0', '1', '0', '0', '0', '1', '0', '0', '0', '0'],\n",
       " ['0', '1', '0', '0', '0', '1', '1', '0', '1', '0'],\n",
       " ['0', '1', '1', '0', '0', '1', '1', '1', '1', '0'],\n",
       " ['1', '1', '1', '0', '1', '1', '1', '1', '0', '0'],\n",
       " ['1', '1', '0', '0', '1', '1', '0', '1', '0', '0'],\n",
       " ['0', '0', '0', '0', '1', '1', '0', '0', '0', '0'],\n",
       " ['0', '1', '0', '1', '0', '0', '0', '0', '1', '1'],\n",
       " ['0', '1', '0', '0', '1', '1', '1', '1', '1', '0'],\n",
       " ['0', '1', '1', '0', '0', '1', '0', '1', '0', '0'],\n",
       " ['1', '1', '0', '0', '1', '1', '1', '0', '0', '0'],\n",
       " ['0', '1', '0', '0', '1', '1', '0', '1', '1', '0'],\n",
       " ['0', '1', '1', '0', '0', '1', '0', '0', '0', '0'],\n",
       " ['1', '1', '0', '0', '1', '1', '1', '0', '1', '0'],\n",
       " ['0', '1', '1', '0', '1', '1', '0', '1', '1', '0'],\n",
       " ['1', '1', '1', '0', '1', '1', '0', '0', '0', '0'],\n",
       " ['1', '1', '0', '0', '1', '1', '0', '0', '1', '0'],\n",
       " ['0', '0', '1', '0', '1', '1', '0', '0', '1', '0'],\n",
       " ['1', '1', '1', '1', '1', '1', '0', '0', '1', '1'],\n",
       " ['1', '1', '0', '0', '1', '1', '0', '0', '1', '0']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"NetworkTransition.txt0_90.txt\") as nt:\n",
    "    mainData = nt.readlines()\n",
    "mainData = [i.strip(\" \\n\").split(\" \") for i in mainData]\n",
    "mainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('models_dict.pkl', 'rb') as file:\n",
    "#     loaded_models_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Directory where models are saved\n",
    "save_dir = 'M/models6'\n",
    "\n",
    "# Initialize the dictionary to store models\n",
    "loaded_models_dict = {}\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for file_name in os.listdir(save_dir):\n",
    "    if file_name.endswith('.keras'):\n",
    "        # Extract key and sub_key from the file name\n",
    "        # Assuming file names are in the format \"model_key_sub_key.keras\"\n",
    "        parts = file_name.split('_')\n",
    "        key = int(parts[1])  # Convert to integer, assuming keys are integers\n",
    "        sub_key = int(parts[2].split('.')[0])  # Extract sub_key and remove '.keras'\n",
    "\n",
    "        # Load the model\n",
    "        model_path = os.path.join(save_dir, file_name)\n",
    "        model = load_model(model_path)\n",
    "\n",
    "        # Store the model in the dictionary\n",
    "        if key not in loaded_models_dict:\n",
    "            loaded_models_dict[key] = {}\n",
    "        loaded_models_dict[key][sub_key] = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_combinations_with_indices(arr, r):\n",
    "    n = len(arr)\n",
    "    indices = list(range(r))\n",
    "    result = []\n",
    "\n",
    "    while True:\n",
    "        # Create a dictionary with index-value pairs\n",
    "        combination_dict = {indices[i]: arr[indices[i]] for i in range(r)}\n",
    "        result.append(combination_dict)\n",
    "\n",
    "        # Find the rightmost index that can be incremented\n",
    "        for i in reversed(range(r)):\n",
    "            if indices[i] != i + n - r:\n",
    "                break\n",
    "        else:\n",
    "            return result  # No more combinations can be generated\n",
    "\n",
    "        # Increment this index\n",
    "        indices[i] += 1\n",
    "\n",
    "        # Update the indices that follow\n",
    "        for j in range(i + 1, r):\n",
    "            indices[j] = indices[j - 1] + 1\n",
    "\n",
    "def generate_permutations_with_indices(arr, r):\n",
    "    from itertools import permutations\n",
    "    n = len(arr)\n",
    "    result = []\n",
    "\n",
    "    # Generate all possible permutations using indices\n",
    "    for perm in permutations(range(n), r):\n",
    "        # Create a dictionary with index-value pairs\n",
    "        permutation_dict = {i: arr[i] for i in perm}\n",
    "        result.append(permutation_dict)\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_elements_from_row(data, row, indexListToRemove):\n",
    "    selected_row = data[row]\n",
    "    result = [val for idx, val in enumerate(selected_row) if idx not in indexListToRemove]\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: {'targetGenes': (1,), 'mismatch': 0}, 6: {'targetGenes': (4,), 'mismatch': 0}, 8: {'targetGenes': (7,), 'mismatch': 0}, 9: {'targetGenes': (1,), 'mismatch': 0}, 0: {'targetGenes': (2,), 'mismatch': 0}}\n"
     ]
    }
   ],
   "source": [
    "from boolF import getBoolF\n",
    "print(getBoolF(\"NetworkTransition.txt0_90.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* BOOLF RES ***********\n",
      "{3: {'targetGenes': (1,), 'mismatch': 0}, 6: {'targetGenes': (4,), 'mismatch': 0}, 8: {'targetGenes': (7,), 'mismatch': 0}, 9: {'targetGenes': (1,), 'mismatch': 0}, 0: {'targetGenes': (2,), 'mismatch': 0}}\n",
      "********* BOOLF RES ***********\n",
      "********* NN INFERENCE ***********\n",
      "**************************************************\n",
      "Target gene Index: 0\n",
      "**************************************************\n",
      "Target gene Index: 1\n",
      "[3, 6, 8, 9, 0, 1]\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:00<00:11,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous minMismatch: 1000000   Improved: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:01<00:10,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous minMismatch: 9   Improved: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 3/15 [00:02<00:09,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous minMismatch: 8   Improved: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:12<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: {'targetGenes': (1,), 'mismatch': 0}, 6: {'targetGenes': (4,), 'mismatch': 0}, 8: {'targetGenes': (7,), 'mismatch': 0}, 9: {'targetGenes': (1,), 'mismatch': 0}, 0: {'targetGenes': (2,), 'mismatch': 0}, 1: {'targetGenes': (5,), 'mismatch': 3}}\n",
      "**************************************************\n",
      "Target gene Index: 2\n",
      "[3, 6, 8, 9, 0, 2]\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:00<00:12,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous minMismatch: 1000000   Improved: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:12<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: {'targetGenes': (1,), 'mismatch': 0}, 6: {'targetGenes': (4,), 'mismatch': 0}, 8: {'targetGenes': (7,), 'mismatch': 0}, 9: {'targetGenes': (1,), 'mismatch': 0}, 0: {'targetGenes': (2,), 'mismatch': 0}, 1: {'targetGenes': (5,), 'mismatch': 3}, 2: {'targetGenes': (1,), 'mismatch': 11}}\n",
      "**************************************************\n",
      "Target gene Index: 3\n",
      "**************************************************\n",
      "Target gene Index: 4\n",
      "[3, 6, 8, 9, 0, 4]\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:00<00:11,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous minMismatch: 1000000   Improved: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 2/15 [00:01<00:10,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous minMismatch: 6   Improved: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:12<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: {'targetGenes': (1,), 'mismatch': 0}, 6: {'targetGenes': (4,), 'mismatch': 0}, 8: {'targetGenes': (7,), 'mismatch': 0}, 9: {'targetGenes': (1,), 'mismatch': 0}, 0: {'targetGenes': (2,), 'mismatch': 0}, 1: {'targetGenes': (5,), 'mismatch': 3}, 2: {'targetGenes': (1,), 'mismatch': 11}, 4: {'targetGenes': (2,), 'mismatch': 5}}\n",
      "**************************************************\n",
      "Target gene Index: 5\n",
      "[3, 6, 8, 9, 0, 5]\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:00<00:12,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous minMismatch: 1000000   Improved: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [00:09<00:04,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous minMismatch: 1   Improved: 0\n",
      "{3: {'targetGenes': (1,), 'mismatch': 0}, 6: {'targetGenes': (4,), 'mismatch': 0}, 8: {'targetGenes': (7,), 'mismatch': 0}, 9: {'targetGenes': (1,), 'mismatch': 0}, 0: {'targetGenes': (2,), 'mismatch': 0}, 1: {'targetGenes': (5,), 'mismatch': 3}, 2: {'targetGenes': (1,), 'mismatch': 11}, 4: {'targetGenes': (2,), 'mismatch': 5}, 5: {'targetGenes': (1, 2, 4), 'mismatch': 0}}\n",
      "**************************************************\n",
      "Target gene Index: 6\n",
      "**************************************************\n",
      "Target gene Index: 7\n",
      "[3, 6, 8, 9, 0, 7]\n",
      "15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 1/15 [00:00<00:11,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous minMismatch: 1000000   Improved: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 5/15 [00:04<00:08,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous minMismatch: 12   Improved: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 7/15 [00:05<00:06,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous minMismatch: 9   Improved: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 10/15 [00:08<00:04,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous minMismatch: 8   Improved: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 11/15 [00:09<00:03,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous minMismatch: 7   Improved: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:12<00:00,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: {'targetGenes': (1,), 'mismatch': 0}, 6: {'targetGenes': (4,), 'mismatch': 0}, 8: {'targetGenes': (7,), 'mismatch': 0}, 9: {'targetGenes': (1,), 'mismatch': 0}, 0: {'targetGenes': (2,), 'mismatch': 0}, 1: {'targetGenes': (5,), 'mismatch': 3}, 2: {'targetGenes': (1,), 'mismatch': 11}, 4: {'targetGenes': (2,), 'mismatch': 5}, 5: {'targetGenes': (1, 2, 4), 'mismatch': 0}, 7: {'targetGenes': (1, 2, 4), 'mismatch': 6}}\n",
      "**************************************************\n",
      "Target gene Index: 8\n",
      "**************************************************\n",
      "Target gene Index: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from boolF import getBoolF\n",
    "size = 1\n",
    "ff = []\n",
    "\n",
    "print(\"********* BOOLF RES ***********\")\n",
    "temp1 = getBoolF(\"NetworkTransition.txt0_90.txt\")\n",
    "print(temp1)\n",
    "print(\"********* BOOLF RES ***********\")\n",
    "print(\"********* NN INFERENCE ***********\")\n",
    "timeStamp = 20\n",
    "numOfGenes = 10 \n",
    "tgI = 0\n",
    "finalResult = getBoolF(\"NetworkTransition.txt0_90.txt\")\n",
    "\n",
    "while tgI != numOfGenes:\n",
    "    minMismatch = 1000000\n",
    "    datasetDict = {}\n",
    "    print(\"*\"*50)\n",
    "    print(f\"Target gene Index: {tgI}\")\n",
    "    temp1 = getBoolF(\"NetworkTransition.txt0_90.txt\")\n",
    "    indexListToRemove = []\n",
    "    for k, v in temp1.items():\n",
    "        indexListToRemove.append(k)\n",
    "    \n",
    "    if tgI in indexListToRemove:\n",
    "        tgI+=1\n",
    "        continue\n",
    "    else:\n",
    "        indexListToRemove.append(tgI)\n",
    "    \n",
    "    print(indexListToRemove)\n",
    "    \n",
    "    yList = [i[tgI] for i in mainData]\n",
    "    for t0 in range(timeStamp):\n",
    "        if t0+1 == timeStamp or tgI == numOfGenes:\n",
    "            break\n",
    "        # x = mainData[t0][:tgI] + mainData[t0][tgI+1:]\n",
    "        x = mainData[t0]\n",
    "        # x = remove_elements_from_row(mainData, t0, indexListToRemove)\n",
    "        alreadyTaken = {}\n",
    "\n",
    "        x = [float(v) for v in x]\n",
    "        for r in range(1, len(x) + 1):\n",
    "            comb = generate_combinations_with_indices(x, r)\n",
    "            for cc in comb:\n",
    "                keyList = []\n",
    "                valList = []\n",
    "                # print(i)\n",
    "                for k, v in cc.items():\n",
    "                    if k in indexListToRemove:\n",
    "                        continue\n",
    "                    keyList.append(k)\n",
    "                    valList.append(v)\n",
    "                if len(keyList) == 0:\n",
    "                    continue\n",
    "                # print(f\"KEYS: {keyList}   VALS: {valList}\")\n",
    "                if tuple(keyList) not in alreadyTaken:\n",
    "                    alreadyTaken[tuple(keyList)] = 1\n",
    "                    if tuple(keyList) not in datasetDict:\n",
    "                        datasetDict[tuple(keyList)] = []\n",
    "\n",
    "                    datasetDict[tuple(keyList)].append(valList)\n",
    "        \n",
    "    \n",
    "    print(len(datasetDict))\n",
    "    for k, v in tqdm(datasetDict.items(), total=len(datasetDict)):\n",
    "        x = v\n",
    "        predList = []\n",
    "        probPred = []\n",
    "        \n",
    "        # print(k, v)\n",
    "        for p in x:\n",
    "            predData = np.array([p])\n",
    "            predictions = loaded_models_dict[tgI][len(p)].predict(predData, verbose=0)\n",
    "            # threshold = 0.13\n",
    "            # prediction = [1.0 if pred > threshold else 0.0 for pred in predictions]\n",
    "            # predList.append(prediction[0])\n",
    "            probPred.append(list(predictions)[0][0])\n",
    "\n",
    "        max_value = max(probPred) - 0.1\n",
    "\n",
    "        predList = [1 if value >= max_value else 0 for value in probPred]\n",
    "        yy = yList[1:]\n",
    "        yy = [float(b) for b in yy]\n",
    "        mismatches = sum([1 for pred, actual in zip(predList, yy) if pred != actual])\n",
    "\n",
    "        if mismatches < minMismatch:\n",
    "            print(f\"Previous minMismatch: {minMismatch}   Improved: {mismatches}\")\n",
    "            minMismatch = mismatches\n",
    "            finalResult[tgI] = {\"targetGenes\": k, \"mismatch\": mismatches}\n",
    "            if mismatches == 0:\n",
    "                break\n",
    "\n",
    "        # finalModels[tgI] = allModels\n",
    "    tgI+=1\n",
    "    print(finalResult)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3: {'targetGenes': (1,), 'mismatch': 0},\n",
       " 6: {'targetGenes': (4,), 'mismatch': 0},\n",
       " 8: {'targetGenes': (7,), 'mismatch': 0},\n",
       " 9: {'targetGenes': (1,), 'mismatch': 0},\n",
       " 0: {'targetGenes': (2,), 'mismatch': 0},\n",
       " 1: {'targetGenes': (5,), 'mismatch': 3},\n",
       " 2: {'targetGenes': (1,), 'mismatch': 11},\n",
       " 4: {'targetGenes': (2,), 'mismatch': 5},\n",
       " 5: {'targetGenes': (1, 2, 4), 'mismatch': 0},\n",
       " 7: {'targetGenes': (1, 2, 4), 'mismatch': 6}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalResult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {1: <Sequential name=sequential, built=True>,\n",
       "  2: <Sequential name=sequential_1, built=True>,\n",
       "  3: <Sequential name=sequential_2, built=True>,\n",
       "  4: <Sequential name=sequential_3, built=True>,\n",
       "  5: <Sequential name=sequential_4, built=True>},\n",
       " 1: {1: <Sequential name=sequential_5, built=True>,\n",
       "  2: <Sequential name=sequential_6, built=True>,\n",
       "  3: <Sequential name=sequential_7, built=True>,\n",
       "  4: <Sequential name=sequential_8, built=True>,\n",
       "  5: <Sequential name=sequential_9, built=True>},\n",
       " 2: {1: <Sequential name=sequential_10, built=True>,\n",
       "  2: <Sequential name=sequential_11, built=True>,\n",
       "  3: <Sequential name=sequential_12, built=True>,\n",
       "  4: <Sequential name=sequential_13, built=True>,\n",
       "  5: <Sequential name=sequential_14, built=True>},\n",
       " 3: {1: <Sequential name=sequential_15, built=True>,\n",
       "  2: <Sequential name=sequential_16, built=True>,\n",
       "  3: <Sequential name=sequential_17, built=True>,\n",
       "  4: <Sequential name=sequential_18, built=True>,\n",
       "  5: <Sequential name=sequential_19, built=True>},\n",
       " 4: {1: <Sequential name=sequential_20, built=True>,\n",
       "  2: <Sequential name=sequential_21, built=True>,\n",
       "  3: <Sequential name=sequential_22, built=True>,\n",
       "  4: <Sequential name=sequential_23, built=True>,\n",
       "  5: <Sequential name=sequential_24, built=True>},\n",
       " 7: {1: <Sequential name=sequential_25, built=True>,\n",
       "  2: <Sequential name=sequential_26, built=True>,\n",
       "  3: <Sequential name=sequential_27, built=True>,\n",
       "  4: <Sequential name=sequential_28, built=True>,\n",
       "  5: <Sequential name=sequential_29, built=True>}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_models_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_actual_data(file_path, value_dict):\n",
    "    actual_data = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = line.split()  # Split the line into words\n",
    "            if not parts:\n",
    "                continue  # Skip empty lines\n",
    "            key = value_dict[parts[0]]  # Map the first item (key) using the dictionary\n",
    "            actual_data[key] = set(value_dict[part] for part in parts[1:] if part in value_dict)  # Map the rest of the line\n",
    "    return actual_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: set(),\n",
       " 1: {0, 9},\n",
       " 2: {0, 9},\n",
       " 3: {2},\n",
       " 4: {3, 6, 7, 9},\n",
       " 5: {6, 9, 10},\n",
       " 6: {9, 10},\n",
       " 7: {1, 6, 8},\n",
       " 8: {3, 5, 6, 7, 9},\n",
       " 9: {4, 6, 7, 8, 10},\n",
       " 10: {7, 9}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cell_cycle_dict = {\n",
    "    \"Cln3\": 0,\n",
    "    \"MBF\": 1,\n",
    "    \"SBF\": 2,\n",
    "    \"Cln1\": 3,\n",
    "    \"Cdh1\": 4,\n",
    "    \"Swi5\": 5,\n",
    "    \"Cdc20\": 6,\n",
    "    \"Clb5\": 7,\n",
    "    \"Sic1\": 8,\n",
    "    \"Clb1\": 9,\n",
    "    \"Mcm1\": 10\n",
    "}\n",
    "actual_data = read_actual_data(\"OrigData/new.txt\", cell_cycle_dict)\n",
    "actual_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_actual_data(file_path):\n",
    "    actual_data = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            parts = list(map(int, line.split()))\n",
    "            key = parts[0]\n",
    "            actual_data[key] = set(parts[1:])\n",
    "    return actual_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: {1, 3},\n",
       " 1: {2, 7, 8},\n",
       " 2: {5, 6},\n",
       " 3: {0, 6, 7},\n",
       " 4: {0},\n",
       " 5: {2, 6},\n",
       " 6: {2},\n",
       " 7: {0, 2, 5, 8},\n",
       " 8: {4},\n",
       " 9: {5}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_data = read_actual_data(\"New Text Document.txt\")\n",
    "actual_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
